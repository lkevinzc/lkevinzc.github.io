<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Zichen Liu</title>

    <meta name="author" content="Zichen Liu">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-TNWLGQEKYM"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-TNWLGQEKYM');
    </script>
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Zichen Liu 刘梓辰
                </p>
                <p class="code" style="text-align:center">
                    liuzc , sea.com  |  zichen , comp.nus.edu.sg
                </p>
                <p>I'm a research engineer at <a href="https://sail.sea.com" target="_blank">Sea AI Lab</a>, and a CS PhD student at National University of Singapore, advised by <a href="https://scholar.google.com/citations?user=8PCrLgwAAAAJ&hl=en" target="_blank">Prof. Lee Wee Sun</a> and <a href="https://scholar.google.com.sg/citations?user=BGONmkIAAAAJ&hl=en" target="_blank">Dr. Lin Min</a>.
                </p>
                <p>
                    I obtained my Bachelor degree in EE from NUS, advised by <a href="https://scholar.google.com.sg/citations?user=Q8iay0gAAAAJ&hl=en" target="_blank">Dr. Feng Jiashi</a>.
                </p>
                <p>
                    I mainly work on reinforcement learning, with a focus on continual learning and its application to LLM reasoning.
                </p>
                <p style="text-align:center">
                  <!-- <a href="zcCV.pdf" target="_blank">CV</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.com/citations?user=v8nb9cgAAAAJ&hl=en" target="_blank">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/lkevinzc" target="_blank">Github</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/zzlccc" target="_blank">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/lkevinzc/" target="_blank">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="me.jpg"><img style="width:100%;max-width:100%;object-fit: cover;" alt="profile photo" src="me.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Publication</h2>
                <p>
                (Please see the Google Scholar page for the up-to-date paper list)
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
            <tr>
              <td style="padding:10px;width:25%;vertical-align:middle;text-align:center;">
                <img src="sea.jpg" alt="clean-usnob" width="240" height="168">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/pdf/2411.01493" target="_blank">
                  <span class="papertitle">Sample-Efficient Alignment for LLMs</span>
                </a>
                <br>
                <strong>Zichen Liu</strong>, 
                <a href="https://cameron-chen.github.io/" target="_blank">Changyu Chen</a>, 
                <a href="https://duchao0726.github.io/" target="_blank">Chao Du</a>, 
                <a href="https://www.comp.nus.edu.sg/~leews/" target="_blank">Wee Sun Lee</a>,
                <a href="https://linmin.me/" target="_blank">Min Lin</a>
                <br>
                <em>LanGame @ Advances in Neural Information Processing Systems (NeurIPS)</em> 2024
                <br>
                <a href="https://arxiv.org/pdf/2411.01493.pdf" target="_blank">pdf</a> 
                / <a href="https://github.com/sail-sg/oat" target="_blank">code</a>
                / <details>
                    <summary>
                      bibtex
                    </summary>
                    <bib>
                      @article{
                        liu2024sea,
                        title={Sample-Efficient Alignment for LLMs},
                        author={Zichen Liu and Changyu Chen and Chao Du and Wee Sun Lee and Min Lin},
                        journal={arXiv preprint arXiv:2411.01493},
                        year={2024}
                      }
                    </bib>
                  </details>
                <p>Through the lens of contextual dueling bandits, we propose a principled Thompson sampling algorithm for LLM online exploration, addressing both explore & exploit and best arm identification settings.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:10px;width:25%;vertical-align:middle;text-align:center;">
                <img src="dice.jpg" alt="clean-usnob" width="240" height="143">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/pdf/2406.09760" target="_blank">
                  <span class="papertitle">Bootstrapping Language Models with DPO Implicit Rewards</span>
                </a>
                <br>
                <a href="https://cameron-chen.github.io/" target="_blank">Changyu Chen*</a>, 
                <strong>Zichen Liu*</strong>, 
                <a href="https://duchao0726.github.io/" target="_blank">Chao Du</a>, 
                <a href="https://p2333.github.io/" target="_blank">Tianyu Pang</a>, 
                <a href="https://siviltaram.github.io/" target="_blank">Qian Liu</a>,
                <a href="http://aruneshsinha.net/" target="_blank">Arunesh Sinha</a>,
                <a href="http://www.mysmu.edu/faculty/pradeepv/" target="_blank">Pradeep Varakantham</a>,
                <a href="https://linmin.me/" target="_blank">Min Lin</a>
                <br>
                <em>International Conference on Learning Representations (ICLR)</em> 2025
                <br>
                <a href="https://arxiv.org/pdf/2406.09760" target="_blank">pdf</a> 
                / <a href="https://github.com/sail-sg/dice" target="_blank">code</a>
                / <details>
                    <summary>
                      bibtex
                    </summary>
                    <bib>
                      @inproceedings{chen2025bootstrapping,
                          title={Bootstrapping Language Models with DPO Implicit Rewards},
                          author={Chen, Changyu and Liu, Zichen and Du, Chao and Pang, Tianyu and Liu, Qian and Sinha, Arunesh and Varakantham, Pradeep and Lin, Min},
                          booktitle={International Conference on Learning Representations},
                          year={2025},
                        }
                    </bib>
                  </details>
                <p>A language model trained with <a href="https://arxiv.org/pdf/2305.18290" target="_blank">DPO</a> provides implicit rewards for self-improvement using online reinforcement learning from AI feedback!</p>
              </td>
            </tr>

            
            <tr>
              <td style="padding:10px;width:25%;vertical-align:middle;text-align:center;">
                <img src="losse.jpg" alt="clean-usnob" width="240" height="191">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/pdf/2401.13034.pdf" target="_blank">
                  <span class="papertitle">Locality Sensitive Sparse Encoding for Learning World Models Online</span>
                </a>
                <br>
                <strong>Zichen Liu</strong>, 
                <a href="https://duchao0726.github.io/" target="_blank">Chao Du</a>, 
                <a href="https://www.comp.nus.edu.sg/~leews/" target="_blank">Wee Sun Lee</a>,
                <a href="https://linmin.me/" target="_blank">Min Lin</a>
                <br>
                <em>International Conference on Learning Representations (ICLR)</em> 2024
                <br>
                <a href="https://arxiv.org/pdf/2401.13034.pdf" target="_blank">pdf</a> 
                / <a href="https://gist.github.com/lkevinzc/fa312a0d6758759799340b2f61487080" target="_blank">code</a>
                / <details>
                    <summary>
                      bibtex
                    </summary>
                    <bib>
                      @inproceedings{liu2024losse,
                          title={Locality Sensitive Sparse Encoding for Learning World Models Online},
                          author={Liu, Zichen and Du, Chao and Lee, Wee Sun and Lin, Min},
                          booktitle={International Conference on Learning Representations},
                          year={2024},
                        }
                    </bib>
                  </details>
                <p>We propose to learn world models purely <strong>online</strong> in the classical <a href="https://dl.acm.org/doi/pdf/10.1145/122344.122377" target="_blank">Dyna</a> framework, using a linear model on non-linear features (an <a href="https://en.wikipedia.org/wiki/Extreme_learning_machine" target="_blank">ELM</a>). Zero forgetting is guaranteed by the linear modeling, making it suitable for continual agents; high-dimensional encoding provides great fitting capacity for complex environments, while its sparsity permits an efficient online update.</p>
              </td>
            </tr>

            <tr>
                <td style="padding:10px;width:25%;vertical-align:middle;text-align:center;">
                  <img src="rosmo.jpg" alt="clean-usnob" width="240" height="112">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/pdf/2210.05980.pdf" target="_blank">
                    <span class="papertitle">Efficient Offline Policy Optimization with a Learned Model</span>
                  </a>
                  <br>
                  <strong>Zichen Liu</strong>, 
                  <a href="https://scholar.google.com.hk/citations?user=TZfjjcAAAAAJ&hl=en" target="_blank">Siyi Li</a>, 
                  <a href="https://www.comp.nus.edu.sg/~leews/" target="_blank">Wee Sun Lee</a>,
                  <a href="https://scholar.google.com.sg/citations?user=DNuiPHwAAAAJ&hl=en" target="_blank">Shuicheng Yan</a>,
                  <a href="https://zhongwen.one/" target="_blank">Zhongwen Xu</a>
                  <br>
                  <em>International Conference on Learning Representations (ICLR)</em> 2023
                  <br>
                  <a href="https://arxiv.org/pdf/2210.05980.pdf" target="_blank">pdf</a> 
                  / <a href="https://github.com/sail-sg/rosmo" target="_blank">code</a>
                  / <details>
                      <summary>
                        bibtex
                      </summary>
                      <bib>
                        @inproceedings{liu2023rosmo,
                            title={Efficient Offline Policy Optimization with a Learned Model},
                            author={Liu, Zichen and Li, Siyi and Lee, Wee Sun and Yan, Shuicheng and Xu, Zhongwen},
                            booktitle={International Conference on Learning Representations},
                            year={2023},
                          }
                      </bib>
                    </details>
                  <p>We investigate the deficiencies of <a href="https://en.wikipedia.org/wiki/Monte_Carlo_tree_search" target="_blank">MCTS</a> in the offline <a href="https://www.furidamu.org/blog/2020/12/22/muzero-intuition/" target="_blank">MuZero</a> algorithm and propose an efficient regularized improvement operator that achieves better sample- and compute-efficiency on the Atari benchmark.</p>
                </td>
              </tr>

            <tr>
                <td style="padding:10px;width:25%;vertical-align:middle;text-align:center;">
                  <img src="envpool.jpg" alt="clean-usnob" width="220" height="163">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://papers.nips.cc/paper_files/paper/2022/file/8caaf08e49ddbad6694fae067442ee21-Paper-Datasets_and_Benchmarks.pdf" target="_blank">
                    <span class="papertitle">EnvPool: A Highly Parallel Reinforcement Learning Environment Execution Engine</span>
                  </a>
                  <br>
                  <a href="https://trinkle23897.github.io/cv/" target="_blank">Jiayi Weng</a>,
                  <a href="https://linmin.me/" target="_blank">Min Lin</a>,
                  <a href="https://costa.sh/" target="_blank">Shengyi Huang</a>,
                  <a href="https://benjamin-eecs.github.io/" target="_blank">Bo Liu</a>,
                  <a href="https://scholar.google.com/citations?user=f8bdrbAAAAAJ&hl=en" target="_blank">Denys Makoviichuk</a>,
                  <a href="https://scholar.google.com/citations?user=rmAcDNkAAAAJ&hl=en" target="_blank">Viktor Makoviychuk</a>,
                  Zichen Liu,
                  <a href="https://www.linkedin.com/in/yufansong/" target="_blank">Yufan Song</a>,
                  <a href="https://www.linkedin.com/in/alicialuo/" target="_blank">Ting Luo</a>,
                  <a >Yukun Jiang</a>,
                  <a href="https://zhongwen.one/" target="_blank">Zhongwen Xu</a>,
                  <a href="https://scholar.google.com.sg/citations?user=DNuiPHwAAAAJ&hl=en" target="_blank">Shuicheng Yan</a>
                  <br>
                  <em>Advances in Neural Information Processing Systems (NeurIPS)</em> 2022
                  <br>
                  <a href="https://papers.nips.cc/paper_files/paper/2022/file/8caaf08e49ddbad6694fae067442ee21-Paper-Datasets_and_Benchmarks.pdf" target="_blank">pdf</a> 
                  / <a href="https://github.com/sail-sg/envpool" target="_blank">code</a> <img alt="GitHub stars" src="https://img.shields.io/github/stars/sail-sg/envpool?style=flat-square" height="13px">
                  / <details>
                      <summary>
                        bibtex
                      </summary>
                      <bib>
                        @inproceedings{weng2022envpool,
                            author = {Weng, Jiayi and Lin, Min and Huang, Shengyi and Liu, Bo and Makoviichuk, Denys and Makoviychuk, Viktor and Liu, Zichen and Song, Yufan and Luo, Ting and Jiang, Yukun and Xu, Zhongwen and Yan, Shuicheng},
                            booktitle = {Advances in Neural Information Processing Systems},
                            title = {Env{P}ool: A Highly Parallel Reinforcement Learning Environment Execution Engine},
                            year = {2022}
                           }
                      </bib>
                    </details>
                  <p>EnvPool provides ultrafast vectorized environments for RL. It allows <a href="https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/#solving-pong-in-5-minutes-with-ppo--envpool" target="_blank">solving Atari Pong in 5 minutes</a> using PPO!</p>
                </td>
              </tr>

            <tr>
              <td style="padding:10px;width:25%;vertical-align:middle;text-align:center;">
                <img src="dance.jpg" alt="clean-usnob" width="240" height="166">
              </td>
              <td width="75%" valign="middle">
                <a href="https://openaccess.thecvf.com/content/WACV2021/papers/Liu_DANCE_A_Deep_Attentive_Contour_Model_for_Efficient_Instance_Segmentation_WACV_2021_paper.pdf" target="_blank">
                  <span class="papertitle">DANCE: A Deep Attentive Contour Model for Efficient Instance Segmentation</span>
                </a>
                <br>
                <strong>Zichen Liu</strong>, 
                <a href="https://scholar.google.com.sg/citations?user=8gm-CYYAAAAJ&hl=en" target="_blank">Jun Hao Liew</a>, 
                <a>Xiangyu Chen</a>,
                <a href="https://scholar.google.com.sg/citations?user=Q8iay0gAAAAJ&hl=en" target="_blank">Jiashi Feng</a>
                <br>
                <em>Winter Conference on Applications of Computer Vision (WACV)</em> 2021
                <br>
                <a href="https://openaccess.thecvf.com/content/WACV2021/papers/Liu_DANCE_A_Deep_Attentive_Contour_Model_for_Efficient_Instance_Segmentation_WACV_2021_paper.pdf" target="_blank">pdf</a> 
                / <a href="https://github.com/lkevinzc/dance" target="_blank">code</a>
                / <details>
                    <summary>
                      bibtex
                    </summary>
                    <bib>
                        @inproceedings{liu2021dance,
                            author    = {Liu, Zichen and Liew, Jun Hao and Chen, Xiangyu and Feng, Jiashi},
                            title     = {DANCE: A Deep Attentive Contour Model for Efficient Instance Segmentation},
                            booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
                            year      = {2021},
                        }
                    </bib>
                  </details>
                <p>We develop an efficient instance segmentation strategy based on the neural snake algorithm and attain SoTA performance on COCO among contour-based methods.</p>
              </td>
            </tr>

          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Open-source software</h2>
              <!-- <p>
                I'm working on reinforcement learning, with a current focus on continual learning.
              </p> -->
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr>
                <td style="padding:10px;width:25%;vertical-align:middle;text-align:center;">
                    <img src="mosec.jpg" alt="clean-usnob" width="240" height="87">
                  </td>
                  <td width="75%" valign="middle">
                    <a href="https://github.com/mosecorg/mosec" target="_blank">
                      <span class="papertitle">Model Serving made Efficient in the Cloud (MOSEC)</span>
                    </a> <img alt="GitHub stars" src="https://img.shields.io/github/stars/mosecorg/mosec?style=social" height="19px">
                    <br>
                    <p>Mosec is a high-performance ML model serving framework built with a <a href="https://tokio.rs/" target="_blank">fast Rust web layer</a>. 
                      It supports all different ML frameworks, such as Jax, PyTorch, TensorFlow, etc., with a super easy coding interface in Python. 
                      Dynamic batching and CPU/GPU pipelines are the core features that can fully exploit your computing machine.</p>
                  </td>
              </tr>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
                <p>I like to play badminton and eat hotpot.</p>
              </td>
            </tr>
          </tbody></table>
        <table align="right">
            <tr>
                <td>
                    <p>
                        <a href="https://github.com/jonbarron/website" target="_blank">Credits</a>
                    </p>
                </td>
            </tr>
        </table>
            
</html>
